{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# from scipy.stats import spearmanr, rankdata\n",
    "# from scipy.spatial.distance import pdist, squareform\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "\n",
    "    files = os.listdir(f'{path}\\\\img\\\\data\\\\')\n",
    "    image = np.empty((len(files), 50, 50, 1))\n",
    "    sample = []\n",
    "    id = []\n",
    "    for i in range(len(files)):\n",
    "        if files[i].split('.')[1] == 'txt':\n",
    "            id.append(i)\n",
    "            data = pd.read_csv(f'{path}\\\\img\\\\data\\\\{files[i]}', sep='\\t', engine='c', na_values=['na', '-', ''], header=None, index_col=None)\n",
    "            image[i, :, :, 0] = data.values\n",
    "            sample.append(files[i].split('.txt')[0])\n",
    "    image = image[id, :, :, :]\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_miRNA(input_data, n):\n",
    "    temp_df = input_data.copy()\n",
    "    temp_df['sums'] = (temp_df.iloc[:,1:].sum(axis = 1))\n",
    "    temp_df = temp_df.sort_values(by='sums', ascending=False)\n",
    "    return temp_df.iloc[0:n,0:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(x_tn, y_lb):\n",
    "    if(x_tn.shape[0]==y_lb.shape[0]):\n",
    "        nonzero_index_r = y_lb.index[y_lb['amount']>0].to_list() #list of zero indices\n",
    "        zero_index_r = y_lb.index[y_lb['amount']==0].to_list() #list of zero indices\n",
    "        zero_index_r = random.choices(zero_index_r, k=len(nonzero_index_r))\n",
    "        final_ind = nonzero_index_r + zero_index_r\n",
    "\n",
    "        x_tn_temp = all_data[final_ind,:,:,:]\n",
    "        y_lb_temp = y_lb.loc[final_ind]\n",
    "        return x_tn_temp, y_lb_temp\n",
    "    else:\n",
    "        print('Dataset Shape did not match!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_test_data(data_main, test_per = 0.2):\n",
    "#     rand_test_index= np.random.randint(0, data_main.shape[0], np.int64(data_main.shape[0]*test_per))\n",
    "#     test_data = data_main[rand_test_index]\n",
    "#     train_data = np.delete(data_main, rand_test_index, axis = 0)\n",
    "\n",
    "#     return train_data, test_data, rand_test_index\n",
    "\n",
    "\n",
    "# train_data, test_data, test_indx = train_test_data(all_data, test_per=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 1 5]\n",
      "[8 7 9 5]\n"
     ]
    }
   ],
   "source": [
    "# xx = [1,2,3,4,5]\n",
    "# yy = [9,8,7,6,5]\n",
    "\n",
    "# xx = np.array(xx)\n",
    "# yy = np.array(yy)\n",
    "\n",
    "\n",
    "# indx = [1,2]\n",
    "# indy = [0,4]\n",
    "\n",
    "# iii = indx+indy\n",
    "\n",
    "# print(xx[iii])\n",
    "# print(yy[iii])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = '..\\\\Results\\\\Table_To_Image_Conversion\\\\Test_1\\\\data'\n",
    "data_path = \"D:\\\\Research\\\\data\\\\processed_dataset\" #lab\n",
    "\n",
    "# tissue_type = 'liver'\n",
    "# tissue_type = 'pancreas'\n",
    "# tissue_type = 'kidney'\n",
    "tissue_type = 'heart'\n",
    "# tissue_type = 'brain_myeloid'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6002, 50, 50, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = load_data(path = f'{data_path}\\\\{tissue_type}')\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 6003)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target = pd.read_csv(f'{data_path}\\\\{tissue_type}\\\\miRNA_bulk.csv')\n",
    "y_target = y_target.drop('Unnamed: 0',axis=1)\n",
    "\n",
    "# y_target = y_target.iloc[:,1:].drop(y_target.index[(y_target.iloc[:,1:].sum(axis = 1) < 1000)]).T\n",
    "\n",
    "\n",
    "y_target.shape\n",
    "\n",
    "# y_target = y_target.iloc[:,1:].T\n",
    "# y_target = y_target.values\n",
    "# y_target\n",
    "\n",
    "# y_target['sums'] = (y_target.iloc[:,1:].sum(axis = 1))\n",
    "# y_target.sort_values(by='sums', ascending=False)\n",
    "# y_target.iloc[0:50,0:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6001</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6002 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      amount\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3         21\n",
       "4          0\n",
       "...      ...\n",
       "5997       0\n",
       "5998      35\n",
       "5999       0\n",
       "6000       0\n",
       "6001       0\n",
       "\n",
       "[6002 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_miRNAs = top_n_miRNA(y_target, 1)\n",
    "\n",
    "top_miRNAs = top_miRNAs.iloc[:,1:].T\n",
    "top_miRNAs = top_miRNAs.rename(columns={top_miRNAs.columns[0]: \"amount\"})\n",
    "sIdex = [i for i in range(top_miRNAs.shape[0])]\n",
    "top_miRNAs = top_miRNAs.set_index([sIdex])\n",
    "top_miRNAs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero_index_r = top_miRNAs.index[top_miRNAs['amount']==0].to_list()\n",
    "# zero_index_r = random.choices(zero_index_r, k=50)\n",
    "\n",
    "# top_miRNAs.drop(zero_index_r, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_miRNAs.shape[0] - top_miRNAs.amount.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_miRNAs.drop(zero_index_r)\n",
    "# all_data_temp = np.delete(all_data, zero_index_r, axis=0)\n",
    "# all_data_temp.shape\n",
    "\n",
    "# nonzero_index_r = top_miRNAs.index[top_miRNAs['amount']>0].to_list() #list of zero indices\n",
    "# zero_index_r = top_miRNAs.index[top_miRNAs['amount']==0].to_list() #list of zero indices\n",
    "# zero_index_r = random.choices(zero_index_r, k=len(nonzero_index_r))\n",
    "# final_ind = nonzero_index_r + zero_index_r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_miRNAs.loc[final_ind]\n",
    "\n",
    "# all_data[final_ind,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def balance_data(x_tn, y_lb):\n",
    "#     if(x_tn.shape[0]==y_lb.shape[0]):\n",
    "#         non_zero = y_lb.shape[0] - y_lb.amount.value_counts()[0] #total amount of non zero samples\n",
    "#         zero_index_r = y_lb.index[y_lb['amount']==0].to_list() #list of zero indices\n",
    "#         del_amnt = len(zero_index_r)-non_zero\n",
    "#         zero_index_r = random.choices(zero_index_r, k=del_amnt)\n",
    "#         x_tn_temp = np.delete(x_tn, zero_index_r, axis=0)\n",
    "#         y_lb_temp = y_lb.drop(zero_index_r, axis=0)\n",
    "#         return x_tn_temp, y_lb_temp\n",
    "#     else:\n",
    "#         print('Dataset Shape did not match!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data, top_miRNAs = balance_data(all_data,top_miRNAs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>amount</th>\n",
       "      <th>ex_lvl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>4749</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>2301</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>1233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>440</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1588 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  amount  ex_lvl\n",
       "0         3      21       0\n",
       "1         5      32       0\n",
       "2         7      93       0\n",
       "3         8      68       0\n",
       "4        15      49       0\n",
       "...     ...     ...     ...\n",
       "1583   4749       0       0\n",
       "1584   2301       0       0\n",
       "1585   1233       0       0\n",
       "1586    440       0       0\n",
       "1587    260       0       0\n",
       "\n",
       "[1588 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sample = top_miRNAs.shape[0]\n",
    "ex_lvl = [0 for l in range(total_sample)]\n",
    "top_miRNAs['ex_lvl'] = ex_lvl\n",
    "top_miRNAs = top_miRNAs.reset_index()\n",
    "top_miRNAs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(total_sample):\n",
    "    if(top_miRNAs['amount'][i]<10):\n",
    "        top_miRNAs['ex_lvl'][i] = 0\n",
    "    else:\n",
    "        top_miRNAs['ex_lvl'][i] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_miRNAs_lbl = top_miRNAs.ex_lvl.values\n",
    "encoded_array = np.zeros((top_miRNAs_lbl.size, top_miRNAs_lbl.max()+1), dtype=int)\n",
    "encoded_array[np.arange(top_miRNAs_lbl.size),top_miRNAs_lbl] = 1 \n",
    "top_miRNAs_lbl = encoded_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_miRNAs_lbl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>amount</th>\n",
       "      <th>ex_lvl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>4749</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>2301</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>1233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>440</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1588 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  amount  ex_lvl\n",
       "0         3      21       1\n",
       "1         5      32       1\n",
       "2         7      93       1\n",
       "3         8      68       1\n",
       "4        15      49       1\n",
       "...     ...     ...     ...\n",
       "1583   4749       0       0\n",
       "1584   2301       0       0\n",
       "1585   1233       0       0\n",
       "1586    440       0       0\n",
       "1587    260       0       0\n",
       "\n",
       "[1588 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_miRNAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# scaled = scaler.fit_transform(top_miRNAs.iloc[:,1:])\n",
    "\n",
    "# top_miRNAs = preprocessing.MinMaxScaler(top_miRNAs.iloc[:,1:].T)\n",
    "# top_miRNAs\n",
    "# top_miRNAs = top_miRNAs.iloc[:,1:].values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_miRNAs = top_miRNAs.T\n",
    "# bins = [0, 99, 199, 299, 399, 499, 599, 699, 799, 899, 999]\n",
    "# labels = ['J', 'I', 'H', 'G', 'F', 'E', 'D','C', 'B', 'A',]\n",
    "\n",
    "def show_grade(smple):\n",
    "    bins = [0, 1, 19, 29, 39, 49, 59, 69, 79, 89, 99, 999]\n",
    "    labels = ['K','J', 'I', 'H', 'G', 'F', 'E', 'D','C', 'B', 'A',]\n",
    "    smple['grade'] = pd.cut(x = smple['amount'], bins = bins, labels = labels, include_lowest = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_grade(top_miRNAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>amount</th>\n",
       "      <th>ex_lvl</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>3898</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>2364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>3807</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>4546</td>\n",
       "      <td>465</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1645</td>\n",
       "      <td>495</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>1350</td>\n",
       "      <td>529</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>226</td>\n",
       "      <td>548</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>1372</td>\n",
       "      <td>725</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1588 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  amount  ex_lvl grade\n",
       "1587    260       0       0     K\n",
       "1109    445       0       0     K\n",
       "1108   3898       0       0     K\n",
       "1107   2364       0       0     K\n",
       "1106   3807       0       0     K\n",
       "...     ...     ...     ...   ...\n",
       "602    4546     465       1     A\n",
       "252    1645     495       1     A\n",
       "231    1350     529       1     A\n",
       "49      226     548       1     A\n",
       "232    1372     725       1     A\n",
       "\n",
       "[1588 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_miRNAs.sort_values(by='amount')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "K    843\n",
       "A    269\n",
       "J    171\n",
       "G     50\n",
       "H     46\n",
       "F     44\n",
       "I     40\n",
       "E     39\n",
       "D     33\n",
       "B     29\n",
       "C     24\n",
       "Name: grade, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_miRNAs['grade'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantiles  = top_miRNAs['grade'].value_counts().quantile([0.25, 0.5, 0.75])\n",
    "quantiles.plot(marker='o')\n",
    "plt.xlabel('Quantile')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Quantiles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(all_data, y_target, test_size=0.1, random_state=5)\n",
    "\n",
    "# print(f'X_train: {X_train.shape}')\n",
    "# print(f'X_test: {X_test.shape}')\n",
    "# print(f'y_train: {y_train.shape}')\n",
    "# print(f'y_test: {y_test.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train_indices, test_indices in kfold.split(all_data):\n",
    "#     y_train, y_val = top_miRNAs.values[train_indices], top_miRNAs.values[test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 32, 93, ...,  0,  0,  0], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top_miRNAs.amount.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def runCNN(train_x_input, train_y_input, val_x, val_y, epoch_num = 10, batch_num = 32):\n",
    "# # Define the model\n",
    "#     model = keras.Sequential()\n",
    "\n",
    "#     # Add the layers to the model\n",
    "#     model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])))\n",
    "#     model.add(keras.layers.BatchNormalization())\n",
    "#     model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "#     model.add(keras.layers.BatchNormalization())\n",
    "#     model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(keras.layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "#     model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "#     # Flatten the output before passing it to the fully connected layers\n",
    "#     model.add(keras.layers.Flatten())\n",
    "\n",
    "#     # Add fully connected layers\n",
    "#     model.add(keras.layers.Dense(128, activation='relu'))\n",
    "#     model.add(keras.layers.Dense(64, activation='relu'))\n",
    "#     model.add(keras.layers.Dense(train_y_input.shape[1], activation='softmax'))\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer='Adam',\n",
    "#                 loss='mse',\n",
    "#                 metrics=['accuracy'])\n",
    "\n",
    "#     # Print the model summary\n",
    "#     print(model.summary())\n",
    "\n",
    "#     history = model.fit(train_x_input, train_y_input, epochs=epoch_num, batch_size=batch_num, validation_data = (val_x, val_y))\n",
    "\n",
    "#     return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(his, tissue_type = ''):\n",
    "    plt.plot(his.history['accuracy'])\n",
    "    plt.plot(his.history['val_accuracy'])\n",
    "    plt.title(f'Model Accuracy: {tissue_type}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(his.history['loss'])\n",
    "    plt.plot(his.history['val_loss'])\n",
    "    plt.title(f'Model Loss: {tissue_type}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 48, 48, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 24, 24, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 22, 22, 32)        18464     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 22, 22, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 11, 11, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 9, 9, 16)          4624      \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 9, 9, 16)         64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 4, 4, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 2, 2, 8)           1160      \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 2, 2, 8)          32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,978\n",
      "Trainable params: 37,738\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "# Add the layers to the model\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(all_data.shape[1], all_data.shape[2], all_data.shape[3])))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(8, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "# Flatten the output before passing it to the fully connected layers\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "# Add fully connected layers\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(top_miRNAs_lbl.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='Adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pan, history_pan = runCNN(train_x_input=X_train, train_y_input=y_train, epoch_num=100, val_x=X_test,  val_y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_history(history_pan, tissue_type=tissue_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40/40 [==============================] - 3s 54ms/step - loss: 0.6948 - accuracy: 0.5709 - val_loss: 0.6886 - val_accuracy: 0.5755\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 0.6593 - accuracy: 0.6126 - val_loss: 0.6857 - val_accuracy: 0.5755\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 1s 16ms/step - loss: 0.6353 - accuracy: 0.6307 - val_loss: 0.6844 - val_accuracy: 0.5755\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.6078 - accuracy: 0.6512 - val_loss: 0.6849 - val_accuracy: 0.5755\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.5592 - accuracy: 0.7031 - val_loss: 0.6846 - val_accuracy: 0.5723\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.5434 - accuracy: 0.7094 - val_loss: 0.6814 - val_accuracy: 0.5786\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.4984 - accuracy: 0.7425 - val_loss: 0.6924 - val_accuracy: 0.5535\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.4420 - accuracy: 0.7795 - val_loss: 0.7982 - val_accuracy: 0.4245\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.4228 - accuracy: 0.7835 - val_loss: 0.7302 - val_accuracy: 0.4277\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.3707 - accuracy: 0.8047 - val_loss: 0.7921 - val_accuracy: 0.4308\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.3023 - accuracy: 0.8472 - val_loss: 0.8577 - val_accuracy: 0.5755\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.3090 - accuracy: 0.8323 - val_loss: 0.8908 - val_accuracy: 0.5881\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.3175 - accuracy: 0.8252 - val_loss: 2.2928 - val_accuracy: 0.5755\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 0.2879 - accuracy: 0.8512 - val_loss: 0.8938 - val_accuracy: 0.4403\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.2701 - accuracy: 0.8677 - val_loss: 0.9329 - val_accuracy: 0.4748\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.2265 - accuracy: 0.8756 - val_loss: 1.0336 - val_accuracy: 0.5503\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.2062 - accuracy: 0.8906 - val_loss: 1.0929 - val_accuracy: 0.5692\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.2180 - accuracy: 0.8890 - val_loss: 1.7523 - val_accuracy: 0.4528\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.2547 - accuracy: 0.8717 - val_loss: 3.8269 - val_accuracy: 0.5755\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.3105 - accuracy: 0.8457 - val_loss: 1.1021 - val_accuracy: 0.4528\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.2376 - accuracy: 0.8803 - val_loss: 1.0837 - val_accuracy: 0.4686\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.2003 - accuracy: 0.9008 - val_loss: 1.7774 - val_accuracy: 0.5472\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 2s 63ms/step - loss: 0.1836 - accuracy: 0.9016 - val_loss: 1.2540 - val_accuracy: 0.5409\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 3s 63ms/step - loss: 0.1725 - accuracy: 0.9071 - val_loss: 1.4559 - val_accuracy: 0.5755\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.1648 - accuracy: 0.9102 - val_loss: 1.6037 - val_accuracy: 0.5063\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 0.1770 - accuracy: 0.9047 - val_loss: 2.3975 - val_accuracy: 0.4560\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.1686 - accuracy: 0.9094 - val_loss: 1.9826 - val_accuracy: 0.5472\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 0.1555 - accuracy: 0.9118 - val_loss: 2.3214 - val_accuracy: 0.4937\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 0.1454 - accuracy: 0.9244 - val_loss: 1.6590 - val_accuracy: 0.5252\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 1s 16ms/step - loss: 0.1497 - accuracy: 0.9165 - val_loss: 1.8635 - val_accuracy: 0.5063\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 1s 17ms/step - loss: 0.1541 - accuracy: 0.9157 - val_loss: 1.8964 - val_accuracy: 0.5943\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 1s 16ms/step - loss: 0.1959 - accuracy: 0.9000 - val_loss: 1.2925 - val_accuracy: 0.5440\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.2870 - accuracy: 0.8669 - val_loss: 2.3645 - val_accuracy: 0.5786\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.2680 - accuracy: 0.8748 - val_loss: 2.2162 - val_accuracy: 0.5566\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.1974 - accuracy: 0.9024 - val_loss: 1.4415 - val_accuracy: 0.4371\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 0.1765 - accuracy: 0.9134 - val_loss: 1.5211 - val_accuracy: 0.4308\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.1547 - accuracy: 0.9260 - val_loss: 2.1631 - val_accuracy: 0.4465\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1547 - accuracy: 0.9228 - val_loss: 1.6972 - val_accuracy: 0.4874\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.1600 - accuracy: 0.9126 - val_loss: 2.8713 - val_accuracy: 0.5597\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.1505 - accuracy: 0.9252 - val_loss: 1.9855 - val_accuracy: 0.4969\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1595 - accuracy: 0.9165 - val_loss: 2.5450 - val_accuracy: 0.4591\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.1763 - accuracy: 0.9126 - val_loss: 1.9882 - val_accuracy: 0.5849\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.1926 - accuracy: 0.8992 - val_loss: 2.7163 - val_accuracy: 0.4686\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.1748 - accuracy: 0.9142 - val_loss: 1.9951 - val_accuracy: 0.4560\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.1467 - accuracy: 0.9299 - val_loss: 1.5498 - val_accuracy: 0.5314\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1330 - accuracy: 0.9331 - val_loss: 2.0353 - val_accuracy: 0.5535\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.1264 - accuracy: 0.9331 - val_loss: 2.3783 - val_accuracy: 0.5660\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 1s 32ms/step - loss: 0.1490 - accuracy: 0.9213 - val_loss: 2.2978 - val_accuracy: 0.5786\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.1427 - accuracy: 0.9236 - val_loss: 2.1800 - val_accuracy: 0.5440\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1345 - accuracy: 0.9260 - val_loss: 2.0076 - val_accuracy: 0.5912\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2.0076 - accuracy: 0.5912\n",
      "Epoch 1/50\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.6444 - accuracy: 0.7803 - val_loss: 0.8553 - val_accuracy: 0.6101\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 2s 37ms/step - loss: 0.3694 - accuracy: 0.8307 - val_loss: 0.8256 - val_accuracy: 0.6132\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2668 - accuracy: 0.8772 - val_loss: 0.6986 - val_accuracy: 0.6069\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.2124 - accuracy: 0.9031 - val_loss: 0.6521 - val_accuracy: 0.6950\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 1s 38ms/step - loss: 0.1863 - accuracy: 0.9142 - val_loss: 0.5788 - val_accuracy: 0.7233\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1760 - accuracy: 0.9087 - val_loss: 0.8277 - val_accuracy: 0.6792\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.1745 - accuracy: 0.9181 - val_loss: 0.9769 - val_accuracy: 0.6478\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.1838 - accuracy: 0.9016 - val_loss: 1.3742 - val_accuracy: 0.6415\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.2024 - accuracy: 0.9016 - val_loss: 0.9686 - val_accuracy: 0.6195\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 2s 59ms/step - loss: 0.2124 - accuracy: 0.8921 - val_loss: 1.7112 - val_accuracy: 0.5377\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2292 - accuracy: 0.8898 - val_loss: 0.8716 - val_accuracy: 0.5912\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.2045 - accuracy: 0.8992 - val_loss: 0.9564 - val_accuracy: 0.5943\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.1679 - accuracy: 0.9031 - val_loss: 1.1601 - val_accuracy: 0.6006\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.1540 - accuracy: 0.9244 - val_loss: 1.0725 - val_accuracy: 0.6352\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.1545 - accuracy: 0.9205 - val_loss: 0.8833 - val_accuracy: 0.6635\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.1526 - accuracy: 0.9197 - val_loss: 1.4095 - val_accuracy: 0.6258\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.1543 - accuracy: 0.9228 - val_loss: 1.0665 - val_accuracy: 0.6824\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.1632 - accuracy: 0.9157 - val_loss: 1.8480 - val_accuracy: 0.6195\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 0.1906 - accuracy: 0.9126 - val_loss: 1.2588 - val_accuracy: 0.6667\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.2167 - accuracy: 0.8866 - val_loss: 0.9262 - val_accuracy: 0.6667\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.1980 - accuracy: 0.8976 - val_loss: 1.0170 - val_accuracy: 0.6195\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 0.1626 - accuracy: 0.9220 - val_loss: 1.1118 - val_accuracy: 0.6572\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.1578 - accuracy: 0.9205 - val_loss: 0.9431 - val_accuracy: 0.6604\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 0.1410 - accuracy: 0.9268 - val_loss: 1.1210 - val_accuracy: 0.6509\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 1s 27ms/step - loss: 0.1416 - accuracy: 0.9228 - val_loss: 1.6569 - val_accuracy: 0.5566\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.1391 - accuracy: 0.9228 - val_loss: 1.3217 - val_accuracy: 0.6509\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.1351 - accuracy: 0.9315 - val_loss: 0.9277 - val_accuracy: 0.7013\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.1512 - accuracy: 0.9173 - val_loss: 1.8752 - val_accuracy: 0.6195\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.1547 - accuracy: 0.9252 - val_loss: 1.2413 - val_accuracy: 0.6352\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.1597 - accuracy: 0.9150 - val_loss: 1.4440 - val_accuracy: 0.6415\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 1s 38ms/step - loss: 0.1495 - accuracy: 0.9236 - val_loss: 1.6681 - val_accuracy: 0.6289\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.1709 - accuracy: 0.9220 - val_loss: 1.4635 - val_accuracy: 0.5597\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.1570 - accuracy: 0.9228 - val_loss: 1.3165 - val_accuracy: 0.6226\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.1651 - accuracy: 0.9181 - val_loss: 1.3905 - val_accuracy: 0.6006\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1477 - accuracy: 0.9197 - val_loss: 1.3590 - val_accuracy: 0.6226\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.1476 - accuracy: 0.9244 - val_loss: 1.6383 - val_accuracy: 0.6415\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.1300 - accuracy: 0.9346 - val_loss: 1.5749 - val_accuracy: 0.6352\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.1393 - accuracy: 0.9268 - val_loss: 1.2912 - val_accuracy: 0.6792\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1345 - accuracy: 0.9307 - val_loss: 0.9321 - val_accuracy: 0.5723\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.1444 - accuracy: 0.9276 - val_loss: 2.2491 - val_accuracy: 0.6258\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.1451 - accuracy: 0.9339 - val_loss: 1.6003 - val_accuracy: 0.6635\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.1245 - accuracy: 0.9417 - val_loss: 1.4615 - val_accuracy: 0.6384\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.1146 - accuracy: 0.9425 - val_loss: 1.2965 - val_accuracy: 0.6918\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.1224 - accuracy: 0.9346 - val_loss: 1.3030 - val_accuracy: 0.6698\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.1259 - accuracy: 0.9386 - val_loss: 1.5876 - val_accuracy: 0.6478\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.1200 - accuracy: 0.9433 - val_loss: 1.2566 - val_accuracy: 0.5189\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.1325 - accuracy: 0.9378 - val_loss: 1.3742 - val_accuracy: 0.6101\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1619 - accuracy: 0.9205 - val_loss: 1.6964 - val_accuracy: 0.5849\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1450 - accuracy: 0.9283 - val_loss: 1.0280 - val_accuracy: 0.6321\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.1146 - accuracy: 0.9504 - val_loss: 2.0319 - val_accuracy: 0.6447\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2.0319 - accuracy: 0.6447\n",
      "Epoch 1/50\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.3238 - accuracy: 0.8811 - val_loss: 1.4723 - val_accuracy: 0.6164\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.2044 - accuracy: 0.9047 - val_loss: 0.8742 - val_accuracy: 0.5881\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1417 - accuracy: 0.9354 - val_loss: 0.6134 - val_accuracy: 0.6855\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.1192 - accuracy: 0.9433 - val_loss: 0.8123 - val_accuracy: 0.7107\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.1160 - accuracy: 0.9394 - val_loss: 0.5942 - val_accuracy: 0.7233\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1074 - accuracy: 0.9386 - val_loss: 0.8088 - val_accuracy: 0.6950\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.1042 - accuracy: 0.9433 - val_loss: 0.8723 - val_accuracy: 0.6761\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1010 - accuracy: 0.9480 - val_loss: 0.5026 - val_accuracy: 0.7642\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.0963 - accuracy: 0.9488 - val_loss: 1.0715 - val_accuracy: 0.6447\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.1064 - accuracy: 0.9472 - val_loss: 1.4316 - val_accuracy: 0.6730\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 0.1052 - accuracy: 0.9425 - val_loss: 1.3696 - val_accuracy: 0.6761\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0992 - accuracy: 0.9449 - val_loss: 0.8613 - val_accuracy: 0.7201\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.1027 - accuracy: 0.9457 - val_loss: 0.8761 - val_accuracy: 0.7327\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.1074 - accuracy: 0.9472 - val_loss: 1.5532 - val_accuracy: 0.6635\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.1896 - accuracy: 0.9181 - val_loss: 2.4013 - val_accuracy: 0.5975\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.1743 - accuracy: 0.9157 - val_loss: 0.8160 - val_accuracy: 0.6761\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.1445 - accuracy: 0.9228 - val_loss: 1.2120 - val_accuracy: 0.5912\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.1203 - accuracy: 0.9457 - val_loss: 0.8773 - val_accuracy: 0.6918\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.1234 - accuracy: 0.9362 - val_loss: 1.3733 - val_accuracy: 0.6667\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.1096 - accuracy: 0.9433 - val_loss: 1.2515 - val_accuracy: 0.6289\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.1089 - accuracy: 0.9441 - val_loss: 1.0986 - val_accuracy: 0.6478\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.1177 - accuracy: 0.9362 - val_loss: 1.7055 - val_accuracy: 0.5849\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.1207 - accuracy: 0.9417 - val_loss: 1.4389 - val_accuracy: 0.6038\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.1169 - accuracy: 0.9465 - val_loss: 0.8799 - val_accuracy: 0.6289\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.1276 - accuracy: 0.9409 - val_loss: 1.0020 - val_accuracy: 0.6447\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.1317 - accuracy: 0.9370 - val_loss: 1.5857 - val_accuracy: 0.6038\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.1210 - accuracy: 0.9449 - val_loss: 1.3031 - val_accuracy: 0.6667\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.1236 - accuracy: 0.9331 - val_loss: 1.0918 - val_accuracy: 0.6918\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1197 - accuracy: 0.9417 - val_loss: 0.9975 - val_accuracy: 0.6384\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 2s 37ms/step - loss: 0.1123 - accuracy: 0.9409 - val_loss: 1.6585 - val_accuracy: 0.6101\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.1111 - accuracy: 0.9472 - val_loss: 1.1192 - val_accuracy: 0.6447\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.1050 - accuracy: 0.9488 - val_loss: 1.5022 - val_accuracy: 0.6509\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0979 - accuracy: 0.9457 - val_loss: 0.8919 - val_accuracy: 0.6792\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 1s 38ms/step - loss: 0.0851 - accuracy: 0.9622 - val_loss: 1.1293 - val_accuracy: 0.6352\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.0924 - accuracy: 0.9433 - val_loss: 1.1802 - val_accuracy: 0.6509\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.0911 - accuracy: 0.9583 - val_loss: 1.4254 - val_accuracy: 0.6195\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 0.1133 - accuracy: 0.9425 - val_loss: 1.0058 - val_accuracy: 0.6006\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.1143 - accuracy: 0.9449 - val_loss: 2.3853 - val_accuracy: 0.5975\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.1005 - accuracy: 0.9512 - val_loss: 1.1951 - val_accuracy: 0.6038\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.0893 - accuracy: 0.9551 - val_loss: 1.1919 - val_accuracy: 0.5943\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.0845 - accuracy: 0.9543 - val_loss: 1.4622 - val_accuracy: 0.5535\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.0808 - accuracy: 0.9575 - val_loss: 1.9618 - val_accuracy: 0.6384\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.0780 - accuracy: 0.9591 - val_loss: 0.9298 - val_accuracy: 0.7107\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 1s 38ms/step - loss: 0.1036 - accuracy: 0.9465 - val_loss: 3.4975 - val_accuracy: 0.5881\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1475 - accuracy: 0.9291 - val_loss: 1.1067 - val_accuracy: 0.5975\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.1655 - accuracy: 0.9339 - val_loss: 1.0427 - val_accuracy: 0.6258\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1427 - accuracy: 0.9291 - val_loss: 1.6331 - val_accuracy: 0.6478\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.1228 - accuracy: 0.9425 - val_loss: 0.7141 - val_accuracy: 0.7390\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0968 - accuracy: 0.9520 - val_loss: 0.7825 - val_accuracy: 0.6950\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0840 - accuracy: 0.9575 - val_loss: 0.6757 - val_accuracy: 0.7044\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6757 - accuracy: 0.7044\n",
      "Epoch 1/50\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.2144 - accuracy: 0.9182 - val_loss: 0.5166 - val_accuracy: 0.7950\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.1951 - accuracy: 0.9056 - val_loss: 0.3946 - val_accuracy: 0.7823\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 0.1313 - accuracy: 0.9434 - val_loss: 0.5305 - val_accuracy: 0.7760\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.1093 - accuracy: 0.9489 - val_loss: 0.3960 - val_accuracy: 0.8391\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.1012 - accuracy: 0.9552 - val_loss: 0.7880 - val_accuracy: 0.5836\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0959 - accuracy: 0.9520 - val_loss: 0.6224 - val_accuracy: 0.7256\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.1010 - accuracy: 0.9473 - val_loss: 0.4571 - val_accuracy: 0.8328\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0962 - accuracy: 0.9544 - val_loss: 0.6405 - val_accuracy: 0.7413\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.1019 - accuracy: 0.9520 - val_loss: 0.7577 - val_accuracy: 0.7603\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.0827 - accuracy: 0.9599 - val_loss: 0.7453 - val_accuracy: 0.7382\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.0957 - accuracy: 0.9552 - val_loss: 0.8798 - val_accuracy: 0.7161\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.0821 - accuracy: 0.9567 - val_loss: 0.9181 - val_accuracy: 0.7287\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.0830 - accuracy: 0.9536 - val_loss: 0.8776 - val_accuracy: 0.6909\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0885 - accuracy: 0.9544 - val_loss: 0.9183 - val_accuracy: 0.7539\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.0865 - accuracy: 0.9552 - val_loss: 0.7522 - val_accuracy: 0.6688\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.0853 - accuracy: 0.9552 - val_loss: 0.4447 - val_accuracy: 0.8454\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.0889 - accuracy: 0.9536 - val_loss: 1.2506 - val_accuracy: 0.6782\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0916 - accuracy: 0.9544 - val_loss: 1.3699 - val_accuracy: 0.6625\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 3s 64ms/step - loss: 0.0845 - accuracy: 0.9583 - val_loss: 0.8801 - val_accuracy: 0.7129\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 0.0757 - accuracy: 0.9630 - val_loss: 1.4391 - val_accuracy: 0.7350\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 2s 50ms/step - loss: 0.0986 - accuracy: 0.9504 - val_loss: 1.8278 - val_accuracy: 0.6972\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.0904 - accuracy: 0.9552 - val_loss: 0.9459 - val_accuracy: 0.6498\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1080 - accuracy: 0.9465 - val_loss: 1.4078 - val_accuracy: 0.7319\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.1690 - accuracy: 0.9300 - val_loss: 1.7556 - val_accuracy: 0.6404\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.2018 - accuracy: 0.9190 - val_loss: 0.9792 - val_accuracy: 0.5804\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.1790 - accuracy: 0.9245 - val_loss: 0.9350 - val_accuracy: 0.5426\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.1402 - accuracy: 0.9308 - val_loss: 1.5906 - val_accuracy: 0.5931\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.0897 - accuracy: 0.9567 - val_loss: 1.0374 - val_accuracy: 0.6246\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.0823 - accuracy: 0.9583 - val_loss: 0.3578 - val_accuracy: 0.8297\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.0985 - accuracy: 0.9536 - val_loss: 0.7512 - val_accuracy: 0.7413\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 0.1050 - accuracy: 0.9489 - val_loss: 1.3821 - val_accuracy: 0.6498\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 0.0963 - accuracy: 0.9536 - val_loss: 0.8376 - val_accuracy: 0.7098\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.1027 - accuracy: 0.9504 - val_loss: 0.4496 - val_accuracy: 0.8233\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.0957 - accuracy: 0.9552 - val_loss: 0.9752 - val_accuracy: 0.6656\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 0.0892 - accuracy: 0.9567 - val_loss: 0.6067 - val_accuracy: 0.8107\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 0.0871 - accuracy: 0.9567 - val_loss: 0.7019 - val_accuracy: 0.7823\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 0.0916 - accuracy: 0.9607 - val_loss: 1.2754 - val_accuracy: 0.6909\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.0924 - accuracy: 0.9607 - val_loss: 1.6405 - val_accuracy: 0.6593\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 0.0908 - accuracy: 0.9536 - val_loss: 1.8365 - val_accuracy: 0.6057\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1162 - accuracy: 0.9481 - val_loss: 0.7759 - val_accuracy: 0.7350\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.1382 - accuracy: 0.9449 - val_loss: 1.4714 - val_accuracy: 0.5268\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.0899 - accuracy: 0.9544 - val_loss: 0.9227 - val_accuracy: 0.5741\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.0930 - accuracy: 0.9528 - val_loss: 0.8385 - val_accuracy: 0.6562\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.0840 - accuracy: 0.9630 - val_loss: 1.1662 - val_accuracy: 0.6278\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.0866 - accuracy: 0.9575 - val_loss: 0.8238 - val_accuracy: 0.7413\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 0.0854 - accuracy: 0.9599 - val_loss: 0.9619 - val_accuracy: 0.6151\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0793 - accuracy: 0.9670 - val_loss: 0.7621 - val_accuracy: 0.7634\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.0699 - accuracy: 0.9622 - val_loss: 0.5149 - val_accuracy: 0.8549\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.0726 - accuracy: 0.9646 - val_loss: 0.8006 - val_accuracy: 0.7603\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.0724 - accuracy: 0.9646 - val_loss: 0.7030 - val_accuracy: 0.7729\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7030 - accuracy: 0.7729\n",
      "Epoch 1/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.1588 - accuracy: 0.9347 - val_loss: 0.9397 - val_accuracy: 0.6246\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 0.1315 - accuracy: 0.9402 - val_loss: 1.0656 - val_accuracy: 0.6625\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 2s 37ms/step - loss: 0.1304 - accuracy: 0.9402 - val_loss: 0.6457 - val_accuracy: 0.7603\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.0949 - accuracy: 0.9544 - val_loss: 0.7488 - val_accuracy: 0.6972\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 1s 32ms/step - loss: 0.0805 - accuracy: 0.9654 - val_loss: 0.5087 - val_accuracy: 0.8265\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.0872 - accuracy: 0.9607 - val_loss: 1.2578 - val_accuracy: 0.5804\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 0.0874 - accuracy: 0.9575 - val_loss: 1.4203 - val_accuracy: 0.5615\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.0886 - accuracy: 0.9622 - val_loss: 0.7804 - val_accuracy: 0.7886\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.0868 - accuracy: 0.9591 - val_loss: 0.8670 - val_accuracy: 0.6877\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 0.0827 - accuracy: 0.9614 - val_loss: 1.1380 - val_accuracy: 0.6656\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.0880 - accuracy: 0.9607 - val_loss: 0.7515 - val_accuracy: 0.7729\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 2s 62ms/step - loss: 0.0917 - accuracy: 0.9591 - val_loss: 0.4598 - val_accuracy: 0.8013\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 2s 57ms/step - loss: 0.0775 - accuracy: 0.9662 - val_loss: 0.4793 - val_accuracy: 0.7886\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0690 - accuracy: 0.9701 - val_loss: 0.5953 - val_accuracy: 0.8107\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.0658 - accuracy: 0.9709 - val_loss: 0.3072 - val_accuracy: 0.8644\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.0679 - accuracy: 0.9662 - val_loss: 0.8420 - val_accuracy: 0.7445\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.0651 - accuracy: 0.9717 - val_loss: 1.0246 - val_accuracy: 0.7192\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.0658 - accuracy: 0.9717 - val_loss: 1.4381 - val_accuracy: 0.6530\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.0652 - accuracy: 0.9670 - val_loss: 0.7920 - val_accuracy: 0.7350\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 1s 38ms/step - loss: 0.0562 - accuracy: 0.9740 - val_loss: 0.9075 - val_accuracy: 0.6845\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.0581 - accuracy: 0.9701 - val_loss: 0.4666 - val_accuracy: 0.8139\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 2s 37ms/step - loss: 0.0582 - accuracy: 0.9725 - val_loss: 1.1830 - val_accuracy: 0.5741\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.0776 - accuracy: 0.9630 - val_loss: 2.0642 - val_accuracy: 0.6719\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.0935 - accuracy: 0.9575 - val_loss: 1.6585 - val_accuracy: 0.6467\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.1355 - accuracy: 0.9465 - val_loss: 1.4884 - val_accuracy: 0.6877\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.1229 - accuracy: 0.9457 - val_loss: 1.1144 - val_accuracy: 0.5174\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.0876 - accuracy: 0.9575 - val_loss: 0.8186 - val_accuracy: 0.6562\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.0761 - accuracy: 0.9607 - val_loss: 0.4872 - val_accuracy: 0.7981\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.0668 - accuracy: 0.9677 - val_loss: 0.4454 - val_accuracy: 0.8580\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0726 - accuracy: 0.9693 - val_loss: 0.6308 - val_accuracy: 0.7445\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0679 - accuracy: 0.9709 - val_loss: 1.1523 - val_accuracy: 0.6625\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.0718 - accuracy: 0.9630 - val_loss: 0.8754 - val_accuracy: 0.7161\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.0809 - accuracy: 0.9614 - val_loss: 0.7030 - val_accuracy: 0.6940\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.0714 - accuracy: 0.9607 - val_loss: 1.0163 - val_accuracy: 0.6498\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 0.0611 - accuracy: 0.9717 - val_loss: 0.8606 - val_accuracy: 0.7445\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.0613 - accuracy: 0.9693 - val_loss: 0.7502 - val_accuracy: 0.7003\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 2s 52ms/step - loss: 0.0696 - accuracy: 0.9693 - val_loss: 1.5932 - val_accuracy: 0.5899\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.0547 - accuracy: 0.9764 - val_loss: 1.2600 - val_accuracy: 0.6593\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.0605 - accuracy: 0.9740 - val_loss: 0.7663 - val_accuracy: 0.6877\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.0774 - accuracy: 0.9630 - val_loss: 1.5871 - val_accuracy: 0.7192\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.1181 - accuracy: 0.9473 - val_loss: 1.1388 - val_accuracy: 0.6625\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 2s 55ms/step - loss: 0.0877 - accuracy: 0.9583 - val_loss: 1.2814 - val_accuracy: 0.6530\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.0769 - accuracy: 0.9591 - val_loss: 2.1210 - val_accuracy: 0.6435\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.0733 - accuracy: 0.9740 - val_loss: 1.7897 - val_accuracy: 0.5773\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.0820 - accuracy: 0.9654 - val_loss: 1.3554 - val_accuracy: 0.6530\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.0692 - accuracy: 0.9709 - val_loss: 1.3549 - val_accuracy: 0.5237\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.0866 - accuracy: 0.9630 - val_loss: 1.0910 - val_accuracy: 0.6940\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0744 - accuracy: 0.9685 - val_loss: 1.2100 - val_accuracy: 0.6593\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.1326 - accuracy: 0.9496 - val_loss: 2.1419 - val_accuracy: 0.6372\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.1120 - accuracy: 0.9559 - val_loss: 1.4111 - val_accuracy: 0.7382\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.4111 - accuracy: 0.7382\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "fold_scores = []\n",
    "epoch_num = 50\n",
    "batch_num = 32\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# y_label = top_miRNAs.amount.values\n",
    "\n",
    "for train_indices, test_indices in kfold.split(all_data):\n",
    "    # print('Train: %s | test: %s' % (train_indices, test_indices))\n",
    "\n",
    "\n",
    "    X_train, X_val = all_data[train_indices], all_data[test_indices]\n",
    "    y_train, y_val = top_miRNAs_lbl[train_indices], top_miRNAs_lbl[test_indices]\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=epoch_num, batch_size=batch_num, validation_data = (X_val, y_val))\n",
    "\n",
    "    _, score = model.evaluate(X_val, y_val)\n",
    "    fold_scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.690258514881134"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(fold_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
